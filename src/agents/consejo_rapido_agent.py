# -*- coding: utf-8 -*-
"""
Agente RÃ¡pido de Consejos - Gusano Barrenador
Para panel lateral (drawer) - Respuestas rÃ¡pidas y concisas
"""
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from pydantic import BaseModel, Field
from typing import List
import uuid


class PersistentChatMessageHistory(BaseChatMessageHistory, BaseModel):
    """Historial de chat que persiste mensajes por sesiÃ³n"""
    messages: List[BaseMessage] = Field(default_factory=list)

    def add_message(self, message: BaseMessage) -> None:
        """Agregar mensaje al historial"""
        self.messages.append(message)

    def add_user_message(self, message: str) -> None:
        """Agregar mensaje de usuario"""
        self.add_message(HumanMessage(content=message))

    def add_ai_message(self, message: str) -> None:
        """Agregar mensaje de IA"""
        self.add_message(AIMessage(content=message))

    def clear(self) -> None:
        """Limpiar historial"""
        self.messages = []


class ConsejoRapidoAgent:
    """Agente para consejos rÃ¡pidos sobre el gusano barrenador"""

    def __init__(self, api_key: str, datos_contexto: str = ""):
        """
        Inicializar agente de consejos rÃ¡pidos.

        Args:
            api_key: API key de Anthropic
            datos_contexto: Resumen de datos actuales de YucatÃ¡n
        """
        self.llm = ChatAnthropic(
            model="claude-sonnet-4-5-20250929",
            api_key=api_key,
            max_tokens=500,  # Respuestas cortas para drawer
            temperature=0.7
        )

        self.chat_histories = {}
        self.datos_contexto = datos_contexto

        # System prompt para consejos rÃ¡pidos
        self.system_prompt = f"""Eres un asistente veterinario experto en gusano barrenador, especializado en CONSEJOS RÃPIDOS Y PRÃCTICOS.

CONTEXTO DE DATOS ACTUALES DE YUCATÃN:
{datos_contexto if datos_contexto else "Esperando datos..."}

TU ROL:
- Asistente rÃ¡pido de SENASICA para ganaderos y tÃ©cnicos de campo
- Das consejos CONCISOS y ACCIONABLES (mÃ¡ximo 3-4 lÃ­neas)
- Respondes rÃ¡pido, sin informaciÃ³n excesiva

TIPOS DE PREGUNTAS QUE RECIBES:
- "Â¿QuÃ© municipio priorizar hoy?"
- "Â¿CÃ³mo identificar el gusano?"
- "Â¿QuÃ© hacer si encuentro un caso?"
- "Â¿A quiÃ©n reporto?"
- "Â¿CuÃ¡ndo aplicar tratamiento?"

REGLAS ESTRICTAS:
1. Respuestas MÃXIMO 4 lÃ­neas
2. Usa emojis (âš ï¸, âœ…, ğŸ“, ğŸ“) para claridad
3. Directo al punto, sin teorÃ­a
4. Si necesitan mÃ¡s detalles â†’ recomienda "Pregunta en el Asistente Completo"
5. SIEMPRE incluye datos especÃ­ficos de YucatÃ¡n cuando aplique
6. Termina con un nÃºmero de contacto si es emergencia

FORMATO DE RESPUESTA:
Emoji + Consejo directo + Dato especÃ­fico (si aplica)

EJEMPLO:
Usuario: "Â¿QuÃ© municipio priorizar?"
TÃº: "âš ï¸ **MÃ‰RIDA** tiene 150 casos activos (45% del total).
âœ… Prioriza inspecciones en zona norte.
ğŸ“ Emergencias: 800-751-2100"

SÃ‰ ULTRA CONCISO. Este es un chat rÃ¡pido."""

        # Crear prompt template
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ])

        # Crear chain
        self.chain = self.prompt | self.llm | StrOutputParser()

        # Crear runnable con historial
        self.runnable_chain = RunnableWithMessageHistory(
            self.chain,
            self.get_session_history,
            input_messages_key="question",
            history_messages_key="history"
        )

    def get_session_history(self, session_id: str) -> BaseChatMessageHistory:
        """Obtener o crear historial de sesiÃ³n"""
        if session_id not in self.chat_histories:
            self.chat_histories[session_id] = PersistentChatMessageHistory()
        return self.chat_histories[session_id]

    def actualizar_contexto(self, nuevo_contexto: str):
        """Actualizar contexto con datos frescos"""
        self.datos_contexto = nuevo_contexto
        self.system_prompt = self.system_prompt.split("CONTEXTO DE DATOS")[0] + \
            f"CONTEXTO DE DATOS ACTUALES DE YUCATÃN:\n{nuevo_contexto}\n\n" + \
            self.system_prompt.split("TU ROL:")[1].split("TU ROL:")[0] + "TU ROL:" + \
            self.system_prompt.split("TU ROL:")[1]

    def obtener_consejo(self, pregunta: str, session_id: str = None) -> str:
        """
        Obtener consejo rÃ¡pido.

        Args:
            pregunta: Pregunta del usuario
            session_id: ID de sesiÃ³n (se genera si no existe)

        Returns:
            str: Consejo rÃ¡pido
        """
        if session_id is None:
            session_id = str(uuid.uuid4())

        try:
            respuesta = self.runnable_chain.invoke(
                {"question": pregunta},
                config={"configurable": {"session_id": session_id}}
            )
            return respuesta
        except Exception as e:
            return f"âŒ Error: {str(e)}\n\nğŸ’¡ Intenta reformular tu pregunta."

    def limpiar_historial(self, session_id: str):
        """Limpiar historial de una sesiÃ³n"""
        if session_id in self.chat_histories:
            self.chat_histories[session_id].clear()


# Preguntas sugeridas para el drawer
PREGUNTAS_SUGERIDAS_DRAWER = [
    "Â¿QuÃ© municipio priorizar hoy?",
    "Â¿CÃ³mo identifico el gusano?",
    "Â¿NÃºmero de emergencias?",
    "Tendencia de esta semana",
    "Â¿CuÃ¡ndo aplicar tratamiento?"
]
